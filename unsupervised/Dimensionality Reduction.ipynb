{"cells":[{"cell_type":"markdown","metadata":{},"source":["Principal component analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Kernel PCA\n","\n","# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Importing the dataset\n","dataset = pd.read_csv('Wine.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values\n","\n","# Splitting the dataset into the Training set and Test set\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","\n","# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Applying Kernel PCA\n","from sklearn.decomposition import KernelPCA\n","kpca = KernelPCA(n_components = 2, kernel = 'rbf')\n","X_train = kpca.fit_transform(X_train)\n","X_test = kpca.transform(X_test)\n","\n","# Training the Logistic Regression model on the Training set\n","from sklearn.linear_model import LogisticRegression\n","classifier = LogisticRegression(random_state = 0)\n","classifier.fit(X_train, y_train)\n","\n","# Making the Confusion Matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","y_pred = classifier.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)\n","\n","# Visualising the Training set results\n","from matplotlib.colors import ListedColormap\n","X_set, y_set = X_train, y_train\n","X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n","                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n","plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n","             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n","plt.xlim(X1.min(), X1.max())\n","plt.ylim(X2.min(), X2.max())\n","for i, j in enumerate(np.unique(y_set)):\n","    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n","                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n","plt.title('Logistic Regression (Training set)')\n","plt.xlabel('PC1')\n","plt.ylabel('PC2')\n","plt.legend()\n","plt.show()\n","\n","# Visualising the Test set results\n","from matplotlib.colors import ListedColormap\n","X_set, y_set = X_test, y_test\n","X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n","                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n","plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n","             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n","plt.xlim(X1.min(), X1.max())\n","plt.ylim(X2.min(), X2.max())\n","for i, j in enumerate(np.unique(y_set)):\n","    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n","                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n","plt.title('Logistic Regression (Test set)')\n","plt.xlabel('PC1')\n","plt.ylabel('PC2')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"G8SB1E67TbQy"},"source":["\n","\n","Linear Descriminant analysis\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Linear Discriminant Analysis (LDA)\n","\n","# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Importing the dataset\n","dataset = pd.read_csv('Wine.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values\n","\n","# Splitting the dataset into the Training set and Test set\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","\n","# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Applying LDA\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","lda = LDA(n_components = 2)\n","X_train = lda.fit_transform(X_train, y_train)\n","X_test = lda.transform(X_test)\n","\n","# Training the Logistic Regression model on the Training set\n","from sklearn.linear_model import LogisticRegression\n","classifier = LogisticRegression(random_state = 0)\n","classifier.fit(X_train, y_train)\n","\n","# Making the Confusion Matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","y_pred = classifier.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)\n","\n","# Visualising the Training set results\n","from matplotlib.colors import ListedColormap\n","X_set, y_set = X_train, y_train\n","X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n","                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n","plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n","             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n","plt.xlim(X1.min(), X1.max())\n","plt.ylim(X2.min(), X2.max())\n","for i, j in enumerate(np.unique(y_set)):\n","    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n","                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n","plt.title('Logistic Regression (Training set)')\n","plt.xlabel('LD1')\n","plt.ylabel('LD2')\n","plt.legend()\n","plt.show()\n","\n","# Visualising the Test set results\n","from matplotlib.colors import ListedColormap\n","X_set, y_set = X_test, y_test\n","X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n","                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n","plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n","             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n","plt.xlim(X1.min(), X1.max())\n","plt.ylim(X2.min(), X2.max())\n","for i, j in enumerate(np.unique(y_set)):\n","    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n","                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n","plt.title('Logistic Regression (Test set)')\n","plt.xlabel('LD1')\n","plt.ylabel('LD2')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Kernel PCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xa0qquwNTfvN"},"outputs":[],"source":["# Principal Component Analysis (PCA)\n","\n","# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Importing the dataset\n","dataset = pd.read_csv('Wine.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values\n","\n","# Splitting the dataset into the Training set and Test set\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","\n","# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Applying PCA\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components = 2)\n","X_train = pca.fit_transform(X_train)\n","X_test = pca.transform(X_test)\n","\n","# Training the Logistic Regression model on the Training set\n","from sklearn.linear_model import LogisticRegression\n","classifier = LogisticRegression(random_state = 0)\n","classifier.fit(X_train, y_train)\n","\n","# Making the Confusion Matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","y_pred = classifier.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)\n","\n","# Visualising the Training set results\n","from matplotlib.colors import ListedColormap\n","X_set, y_set = X_train, y_train\n","X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n","                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n","plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n","             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n","plt.xlim(X1.min(), X1.max())\n","plt.ylim(X2.min(), X2.max())\n","for i, j in enumerate(np.unique(y_set)):\n","    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n","                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n","plt.title('Logistic Regression (Training set)')\n","plt.xlabel('PC1')\n","plt.ylabel('PC2')\n","plt.legend()\n","plt.show()\n","\n","# Visualising the Test set results\n","from matplotlib.colors import ListedColormap\n","X_set, y_set = X_test, y_test\n","X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n","                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n","plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n","             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n","plt.xlim(X1.min(), X1.max())\n","plt.ylim(X2.min(), X2.max())\n","for i, j in enumerate(np.unique(y_set)):\n","    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n","                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n","plt.title('Logistic Regression (Test set)')\n","plt.xlabel('PC1')\n","plt.ylabel('PC2')\n","plt.legend()\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOk37dPQ/snB3/0I6+aHHPn","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
